{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 101)\n",
    "pd.set_option(\"display.max_rows\", 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-scope",
   "metadata": {},
   "source": [
    "### Picking up where we left off..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickled DFs generated by query_dfs.py\n",
    "\n",
    "df_orders = pd.read_pickle(\"./pickle/df_orders.pickle\")\n",
    "df_train = pd.read_pickle(\"./pickle/df_train.pickle\")\n",
    "df_prior = pd.read_pickle(\"./pickle/df_prior.pickle\")\n",
    "df_prod_detail = pd.read_pickle(\"./pickle/df_prod_detail.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickled feature DF generated by feature_engineering_1.ipynb\n",
    "X = pd.read_pickle(\"./pickle/X_7.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_orders.eval_set == 'train'\n",
    "len(df_orders[mask].order_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-header",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "royal-pipeline",
   "metadata": {},
   "source": [
    "### Features to Add:\n",
    "\n",
    "**Product features**\n",
    "* `prod_total_sales`: the number of times the product has been purcased in the past (by all users)\n",
    "* `prod_pct_reordered`: product percent of prior transactions that were reorders\n",
    "* `prod_avg_atco`: product average add-to-cart order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-press",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_sales = (df_prior.groupby('product_id')\n",
    "              .agg({\"product_id\": \"count\"})['product_id']\n",
    "              .sort_values(ascending=False))\n",
    "\n",
    "prod_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total sales for each product & add to X\n",
    "\n",
    "X = (X.merge(prod_sales, left_on='product_id', right_index=True)\n",
    "    .drop(columns=\"product_id_x\"))\n",
    "    \n",
    "X.rename(columns={\"product_id_y\": \"prod_prior_sales\"}, inplace=True)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prod_pct_reordered col\n",
    "reorders = df_prior.groupby(\"product_id\").agg({\"reordered\": \"sum\"})\n",
    "reorders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X.merge(reorders, left_on='product_id', right_index=True)\n",
    "     .rename(columns={\"reordered\": \"prod_prior_reorders\"}))\n",
    "del reorders\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"prod_pct_reorders\"] = X.prod_prior_reorders / X.prod_prior_sales\n",
    "X.drop(columns=\"prod_prior_reorders\", inplace=True)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add product avg. add to cart order (prod_avg_atco)\n",
    "atcos = (df_prior.groupby(['product_id'], as_index=False)\n",
    "                                           .agg({'add_to_cart_order': 'mean'}))\n",
    "\n",
    "X = X.merge(atcos, on=\"product_id\").rename(columns={'add_to_cart_order': 'prod_avg_atco'})\n",
    "del atcos\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-sender",
   "metadata": {},
   "source": [
    "### Features to Add\n",
    "\n",
    "**User features**\n",
    "* `user_total_orders`: total number of orders for the user\n",
    "* `user_total_reorders`\n",
    "* `user_pct_reorders`\n",
    "* `user_avg_ippo`: user average items per order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num. total purchases for each user   \n",
    "user_order_counts = (df_orders.groupby(\"user_id\")\n",
    "                     .agg({\"order_number\": \"max\"})\n",
    "                     .rename(columns={\"order_number\": \"user_total_orders\"}))\n",
    "                     \n",
    "                     \n",
    "user_order_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user_total_orders col to X\n",
    "\n",
    "X = X.merge(user_order_counts, how='left', left_on='user_id', right_index=True)\n",
    "\n",
    "del user_order_counts\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add total items per order\n",
    "user_total_items = (df_prior.groupby('user_id', as_index=False)\n",
    " .agg({\"product_id\": \"count\"})\n",
    " .rename(columns={\"product_id\": \"user_total_items_purchased\"}))\n",
    "\n",
    "user_total_items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num_prior_orders = (df_prior.groupby('user_id', as_index=False)\n",
    " .agg({\"order_number\": \"max\"})\n",
    " .rename(columns={\"order_number\": \"user_num_prior_orders\"}))\n",
    "\n",
    "user_avg_ipos = user_num_prior_orders.merge(user_total_items, on='user_id')\n",
    "\n",
    "user_avg_ipos['user_avg_ippo'] = user_avg_ipos.user_total_items_purchased / user_avg_ipos.user_num_prior_orders\n",
    "user_avg_ipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.merge(user_avg_ipos[['user_id', 'user_avg_ippo']], on='user_id')\n",
    "X.drop(columns='user_total_orders', inplace=True)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-delight",
   "metadata": {},
   "source": [
    "### Top Ten Products (reorder percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_prod_detail.merge((X.groupby('product_id', as_index=False)\n",
    " .agg({\"prod_pct_reorders\": \"min\"})), how='left', on='product_id')\n",
    " .sort_values(by=\"prod_pct_reorders\", ascending=False)).reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_prior.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_orders.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_orders.eval_set == 'test'\n",
    "df_orders[mask].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_prior.user_id == 6\n",
    "df_prior[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-guarantee",
   "metadata": {},
   "source": [
    "### More features...\n",
    "* `order_hour_of_day_avg`: already provided in df_train\n",
    "* `days_since_prior_order`: already provided in df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = (df_train.groupby('user_id', as_index=False)\n",
    "               .agg({'days_since_prior_order': 'min',\n",
    "                     'order_hour_of_day':'min'}))\n",
    "\n",
    "X = X.merge(train_feats, on='user_id')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user_avg_spacing and user_avg_time\n",
    "\n",
    "train_merge_cols = ['user_id', 'order_hour_of_day', 'days_since_prior_order']\n",
    "prior_user_stats = (df_prior[train_merge_cols].groupby('user_id', as_index=False)\n",
    "               .agg('mean'))\n",
    "\n",
    "X = (X.merge(prior_user_stats, on='user_id', suffixes=[None, '_avg']))\n",
    "\n",
    "(X.rename(columns={\"order_hour_of_day\": \"user_avg_time\",\n",
    "                   \"days_since_prior_order\": \"user_avg_spacing\"},\n",
    "          inplace=True))\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def split_users(df, test_size=.2, seed=36):\n",
    "\n",
    "    rs = np.random.RandomState(seed)\n",
    "    \n",
    "    # Here, we select a sample (`choice`) from all possible unique users\n",
    "    total_users = df['user_id'].unique()\n",
    "    test_users = rs.choice(total_users, \n",
    "                           size=int(total_users.shape[0] * test_size), \n",
    "                           replace=False)\n",
    "\n",
    "    mask = df['user_id'].isin(test_users)\n",
    "    df_tr = df[~mask] # the '~' means NOT (i.e. includes Bool=False)\n",
    "    df_te = df[mask] \n",
    "\n",
    "    y_tr, y_te = df_tr['in_cart'], df_te['in_cart']\n",
    "    X_tr = df_tr.drop(['product_id','user_id','cart','in_cart','last_cart'],axis=1) \n",
    "    X_te = df_te.drop(['product_id','user_id','cart','in_cart','last_cart'],axis=1)\n",
    "    \n",
    "    print(f\"Actual Test Size: {y_te.shape[0] / df.shape[0]:0.4}\")\n",
    "    \n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results\n",
    "X_tr, X_te, y_tr, y_te = split_users(X)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "lr.fit(X_tr, y_tr)\n",
    "f1_score(lr.predict(X_te), y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-semester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-motor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
